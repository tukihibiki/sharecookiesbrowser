#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# Copyright (C) 2025 [hibiki-YE]
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published
# by the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.

"""
æ™ºèƒ½æµè§ˆå™¨ç™»å½•å·¥å…·
è‡ªåŠ¨åˆ†æç½‘é¡µå¹¶æ™ºèƒ½ç®¡ç†cookies
"""

import asyncio
import json
import requests
from pathlib import Path
from playwright.async_api import async_playwright
import argparse
import sys
import re
from urllib.parse import urlparse
from typing import Dict, List, Optional, Tuple
import time

class WebsiteAnalyzer:
    """ç½‘ç«™åˆ†æå™¨ - æ™ºèƒ½è¯†åˆ«ç½‘ç«™ç±»å‹å’Œcookiesç­–ç•¥"""
    
    def __init__(self):
        # ç½‘ç«™æ¨¡å¼è¯†åˆ«è§„åˆ™
        self.site_patterns = {
            'enterprise_query': {
                'domains': ['alphalawyer.cn', 'qichacha.com', 'tianyancha.com', 'enterprise.com'],
                'keywords': ['ä¼ä¸šæŸ¥è¯¢', 'å·¥å•†ä¿¡æ¯', 'ä¼ä¸šä¿¡æ¯', 'å…¬å¸æŸ¥è¯¢', 'ä¼ä¸šå¾ä¿¡', 'æ³•åŠ¡'],
                'login_keywords': ['å¾®ä¿¡ç™»å½•', 'ä¼ä¸šç™»å½•', 'ç”¨æˆ·ç™»å½•'],
                'strategy': 'shared_enterprise'
            },
            'legal_service': {
                'domains': ['lawfirm.com', 'legal.com', 'lawyer.com'],
                'keywords': ['æ³•å¾‹æœåŠ¡', 'å¾‹å¸ˆ', 'æ³•åŠ¡', 'æ³•å¾‹å’¨è¯¢', 'æ¡ˆä»¶'],
                'login_keywords': ['å¾‹å¸ˆç™»å½•', 'ä¸“ä¸šç™»å½•', 'ä¼šå‘˜ç™»å½•'],
                'strategy': 'professional_shared'
            },
            'government': {
                'domains': ['gov.cn', '.gov.', 'court.gov.cn'],
                'keywords': ['æ”¿åºœ', 'æ³•é™¢', 'æ”¿åŠ¡', 'å®˜æ–¹', 'è¡Œæ”¿'],
                'login_keywords': ['ç»Ÿä¸€ç™»å½•', 'å®åç™»å½•', 'æ”¿åŠ¡ç™»å½•'],
                'strategy': 'secure_isolated'
            },
            'finance': {
                'domains': ['bank.com', 'finance.com', 'pay.com'],
                'keywords': ['é“¶è¡Œ', 'æ”¯ä»˜', 'é‡‘è', 'è´¢åŠ¡', 'è´¦æˆ·'],
                'login_keywords': ['ç½‘é“¶ç™»å½•', 'å®‰å…¨ç™»å½•', 'å®åç™»å½•'],
                'strategy': 'secure_isolated'
            },
            'general_business': {
                'domains': ['*.com', '*.cn', '*.net'],
                'keywords': ['ç™»å½•', 'æ³¨å†Œ', 'ä¼šå‘˜', 'ç”¨æˆ·'],
                'login_keywords': ['ç”¨æˆ·ç™»å½•', 'ä¼šå‘˜ç™»å½•', 'è´¦å·ç™»å½•'],
                'strategy': 'standard_shared'
            }
        }
        
        # Cookiesç­–ç•¥é…ç½®
        self.strategies = {
            'shared_enterprise': {
                'name': 'ä¼ä¸šæŸ¥è¯¢å…±äº«æ¨¡å¼',
                'sharing': 'high',
                'security': 'medium',
                'lifetime': 7200,  # 2å°æ—¶
                'description': 'é€‚ç”¨äºä¼ä¸šæŸ¥è¯¢ç±»ç½‘ç«™ï¼Œæ”¯æŒå¤šå®¢æˆ·ç«¯å…±äº«'
            },
            'professional_shared': {
                'name': 'ä¸“ä¸šæœåŠ¡å…±äº«æ¨¡å¼', 
                'sharing': 'medium',
                'security': 'high',
                'lifetime': 3600,  # 1å°æ—¶
                'description': 'é€‚ç”¨äºä¸“ä¸šæœåŠ¡ç½‘ç«™ï¼Œé™åˆ¶å¹¶å‘æ•°çš„å…±äº«'
            },
            'secure_isolated': {
                'name': 'å®‰å…¨éš”ç¦»æ¨¡å¼',
                'sharing': 'none',
                'security': 'highest',
                'lifetime': 1800,  # 30åˆ†é’Ÿ
                'description': 'é€‚ç”¨äºæ”¿åºœã€é‡‘èç­‰é«˜å®‰å…¨è¦æ±‚ç½‘ç«™ï¼Œä¸å…±äº«'
            },
            'standard_shared': {
                'name': 'æ ‡å‡†å…±äº«æ¨¡å¼',
                'sharing': 'medium',
                'security': 'medium', 
                'lifetime': 3600,  # 1å°æ—¶
                'description': 'é€‚ç”¨äºä¸€èˆ¬å•†åŠ¡ç½‘ç«™çš„æ ‡å‡†å…±äº«ç­–ç•¥'
            }
        }
    
    async def analyze_website(self, page, url: str) -> Dict:
        """åˆ†æç½‘ç«™å¹¶è¿”å›ç­–ç•¥å»ºè®®"""
        try:
            print(f"æ­£åœ¨åˆ†æç½‘ç«™: {url}")
            
            # è§£æURL
            parsed_url = urlparse(url)
            domain = parsed_url.netloc.lower()
            
            # è·å–é¡µé¢æ ‡é¢˜å’Œå†…å®¹
            title = await page.title()
            page_text = await page.inner_text('body')
            
            # æ£€æµ‹ç½‘ç«™ç±»å‹
            site_type = self._detect_site_type(domain, title, page_text)
            
            # è·å–ç­–ç•¥
            strategy = self.strategies.get(site_type['strategy'], self.strategies['standard_shared'])
            
            analysis_result = {
                'url': url,
                'domain': domain,
                'title': title,
                'site_type': site_type,
                'strategy': strategy,
                'timestamp': time.time()
            }
            
            print(f"ç½‘ç«™åˆ†æå®Œæˆ:")
            print(f"  ç½‘ç«™ç±»å‹: {site_type['type']}")
            print(f"  æ¨èç­–ç•¥: {strategy['name']}")
            print(f"  å®‰å…¨çº§åˆ«: {strategy['security']}")
            print(f"  å…±äº«ç­–ç•¥: {strategy['sharing']}")
            
            return analysis_result
            
        except Exception as e:
            print(f"ç½‘ç«™åˆ†æå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤ç­–ç•¥
            return {
                'url': url,
                'domain': urlparse(url).netloc,
                'title': 'Unknown',
                'site_type': {'type': 'unknown', 'strategy': 'standard_shared'},
                'strategy': self.strategies['standard_shared'],
                'timestamp': time.time()
            }
    
    def _detect_site_type(self, domain: str, title: str, content: str) -> Dict:
        """æ£€æµ‹ç½‘ç«™ç±»å‹"""
        content_lower = content.lower()
        title_lower = title.lower()
        
        # æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥ç½‘ç«™ç±»å‹
        for site_type, config in self.site_patterns.items():
            # æ£€æŸ¥åŸŸååŒ¹é…
            if self._match_domains(domain, config['domains']):
                return {'type': site_type, 'strategy': config['strategy'], 'confidence': 0.9}
            
            # æ£€æŸ¥å…³é”®è¯åŒ¹é…
            keyword_score = self._calculate_keyword_score(
                content_lower + ' ' + title_lower, 
                config['keywords'] + config['login_keywords']
            )
            
            if keyword_score > 0.6:
                return {'type': site_type, 'strategy': config['strategy'], 'confidence': keyword_score}
        
        # é»˜è®¤è¿”å›é€šç”¨å•†åŠ¡ç±»å‹
        return {'type': 'general_business', 'strategy': 'standard_shared', 'confidence': 0.3}
    
    def _match_domains(self, domain: str, patterns: List[str]) -> bool:
        """æ£€æŸ¥åŸŸåæ˜¯å¦åŒ¹é…æ¨¡å¼"""
        for pattern in patterns:
            if pattern.startswith('*'):
                suffix = pattern[1:]
                if domain.endswith(suffix):
                    return True
            elif pattern in domain:
                return True
        return False
    
    def _calculate_keyword_score(self, text: str, keywords: List[str]) -> float:
        """è®¡ç®—å…³é”®è¯åŒ¹é…åˆ†æ•°"""
        matches = 0
        for keyword in keywords:
            if keyword in text:
                matches += 1
        return matches / len(keywords) if keywords else 0


class SmartBrowserLogin:
    """æ™ºèƒ½æµè§ˆå™¨ç™»å½•å·¥å…·"""
    
    def __init__(self, server_url="http://localhost:8001"):
        self.server_url = server_url
        self.analyzer = WebsiteAnalyzer()
        self.visited_urls = []
        self.analysis_results = []
        
    async def start_smart_login(self):
        """å¯åŠ¨æ™ºèƒ½ç™»å½•æµç¨‹"""
        print("æ™ºèƒ½æµè§ˆå™¨ç™»å½•å·¥å…·")
        print("=" * 60)
        print("æœ¬å·¥å…·å°†è‡ªåŠ¨åˆ†ææ‚¨è®¿é—®çš„ç½‘ç«™ï¼Œ")
        print("å¹¶æ ¹æ®ç½‘ç«™ç±»å‹é€‰æ‹©æœ€é€‚åˆçš„cookiesç­–ç•¥ã€‚")
        print("=" * 60)
        
        async with async_playwright() as playwright:
            # å¯åŠ¨æµè§ˆå™¨
            browser = await playwright.chromium.launch(
                headless=False,
                args=['--start-maximized']
            )
            
            try:
                context = await browser.new_context(no_viewport=True)
                page = await context.new_page()
                
                # è®¾ç½®é¡µé¢ç›‘æ§
                await self._setup_comprehensive_monitoring(page, context)
                
                # æ‰“å¼€èµ·å§‹é¡µé¢
                await page.goto("https://www.baidu.com")
                
                print("\næµè§ˆå™¨å·²å¯åŠ¨ï¼")
                print("ğŸ’¡ ä½¿ç”¨è¯´æ˜ï¼š")
                print("1. è¯·åœ¨æµè§ˆå™¨ä¸­è®¿é—®ä»»ä½•éœ€è¦ç™»å½•çš„ç½‘ç«™")
                print("2. å®Œæˆç™»å½•æ“ä½œï¼ˆå¾®ä¿¡æ‰«ç ã€å¯†ç ç™»å½•ç­‰ï¼‰")
                print("3. ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹ç™»å½•çŠ¶æ€å¹¶ä¿å­˜cookies")
                print("4. æ”¯æŒå¤šä¸ªç½‘ç«™åŒæ—¶ç™»å½•ï¼Œç³»ç»Ÿä¼šæ™ºèƒ½åˆ†ææ¯ä¸ªç½‘ç«™")
                print("5. ç™»å½•å®ŒæˆåæŒ‰å›è½¦é”®ç»“æŸå¹¶ä¸Šä¼ æ‰€æœ‰cookies")
                print("=" * 60)
                
                # æŒç»­ç›‘æ§ç›´åˆ°ç”¨æˆ·ç»“æŸ
                await self._continuous_monitoring(page, context)
                
                return True
                
            except Exception as e:
                print(f"æ™ºèƒ½ç™»å½•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                return False
            finally:
                await browser.close()

    async def _setup_comprehensive_monitoring(self, page, context):
        """è®¾ç½®å…¨é¢çš„é¡µé¢ç›‘æ§"""
        self.context = context
        self.monitored_domains = set()
        self.login_detected_domains = set()
        self.last_cookie_count = 0
        
        # ç›‘æ§é¡µé¢å¯¼èˆª
        async def on_navigation(page):
            try:
                url = page.url
                if not url.startswith('data:') and not url.startswith('chrome-extension:'):
                    domain = urlparse(url).netloc
                    if domain and domain not in self.monitored_domains:
                        self.monitored_domains.add(domain)
                        print(f"ğŸŒ æ£€æµ‹åˆ°æ–°åŸŸå: {domain}")
                        
                        # å»¶è¿Ÿæ£€æµ‹ä»¥ç¡®ä¿é¡µé¢åŠ è½½å®Œæˆ
                        await asyncio.sleep(2)
                        await self._check_login_status(page, context)
            except Exception as e:
                print(f"å¯¼èˆªç›‘æ§é”™è¯¯: {e}")
        
        # ç›‘æ§cookieså˜åŒ–
        async def on_response(response):
            try:
                # æ£€æŸ¥æ˜¯å¦å¯èƒ½æ˜¯ç™»å½•ç›¸å…³çš„å“åº”
                url = response.url
                if any(keyword in url.lower() for keyword in ['login', 'auth', 'oauth', 'signin', 'wechat']):
                    print(f"ğŸ” æ£€æµ‹åˆ°å¯èƒ½çš„ç™»å½•å“åº”: {url}")
                    await asyncio.sleep(1)  # ç­‰å¾…cookiesè®¾ç½®
                    await self._check_login_status(page, context)
            except Exception as e:
                print(f"å“åº”ç›‘æ§é”™è¯¯: {e}")
        
        page.on('domcontentloaded', on_navigation)
        page.on('response', on_response)

    async def _continuous_monitoring(self, page, context):
        """æŒç»­ç›‘æ§æ¨¡å¼"""
        check_interval = 5  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
        last_check_time = time.time()
        
        print("\nğŸ” å¼€å§‹æŒç»­ç›‘æ§ç™»å½•çŠ¶æ€...")
        
        while True:
            try:
                # å®šæœŸæ£€æŸ¥cookieså˜åŒ–
                current_time = time.time()
                if current_time - last_check_time >= check_interval:
                    await self._periodic_cookie_check(page, context)
                    last_check_time = current_time
                
                # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦è¦ç»“æŸ (Windowså…¼å®¹)
                import sys
                import msvcrt
                if msvcrt.kbhit():
                    char = msvcrt.getch().decode('utf-8', errors='ignore')
                    if char in ['\r', '\n', 'q', 'Q']:  # å›è½¦æˆ–qé”®
                        print("\nç”¨æˆ·è¯·æ±‚ç»“æŸç›‘æ§...")
                        break
                
                await asyncio.sleep(1)
                
            except KeyboardInterrupt:
                break
            except Exception as e:
                print(f"ç›‘æ§è¿‡ç¨‹é”™è¯¯: {e}")
                await asyncio.sleep(5)
        
        # æœ€ç»ˆå¤„ç†æ‰€æœ‰æ£€æµ‹åˆ°çš„cookies
        await self._final_cookie_processing(context)

    async def _check_login_status(self, page, context):
        """æ£€æŸ¥é¡µé¢ç™»å½•çŠ¶æ€"""
        try:
            url = page.url
            domain = urlparse(url).netloc
            
            # è·å–å½“å‰cookies
            current_cookies = await context.cookies()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„è®¤è¯cookies
            auth_cookies = [
                cookie for cookie in current_cookies 
                if any(keyword in cookie['name'].lower() 
                      for keyword in ['session', 'token', 'auth', 'user', 'login', 'jwt', 'openid'])
            ]
            
            if auth_cookies and domain not in self.login_detected_domains:
                self.login_detected_domains.add(domain)
                print(f"ğŸ‰ æ£€æµ‹åˆ° {domain} çš„ç™»å½•çŠ¶æ€!")
                print(f"   è®¤è¯cookies: {len(auth_cookies)} ä¸ª")
                
                # åˆ†æå½“å‰ç½‘ç«™
                analysis_result = await self.analyzer.analyze_website(page, url)
                
                # å¤„ç†cookies
                await self._process_domain_cookies(domain, current_cookies, analysis_result)
                
        except Exception as e:
            print(f"ç™»å½•çŠ¶æ€æ£€æŸ¥é”™è¯¯: {e}")

    async def _periodic_cookie_check(self, page, context):
        """å®šæœŸæ£€æŸ¥cookieså˜åŒ–"""
        try:
            current_cookies = await context.cookies()
            current_count = len(current_cookies)
            
            if current_count > self.last_cookie_count:
                print(f"ğŸª æ£€æµ‹åˆ°cookieså˜åŒ–: {self.last_cookie_count} -> {current_count}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„è®¤è¯cookies
                auth_cookies = [
                    cookie for cookie in current_cookies 
                    if any(keyword in cookie['name'].lower() 
                          for keyword in ['session', 'token', 'auth', 'user', 'login'])
                ]
                
                if auth_cookies:
                    await self._check_login_status(page, context)
                
                self.last_cookie_count = current_count
                
        except Exception as e:
            print(f"å®šæœŸæ£€æŸ¥é”™è¯¯: {e}")

    async def _process_domain_cookies(self, domain, all_cookies, analysis_result):
        """å¤„ç†ç‰¹å®šåŸŸåçš„cookies"""
        try:
            # ç­›é€‰è¯¥åŸŸåç›¸å…³çš„cookies
            domain_cookies = [
                cookie for cookie in all_cookies 
                if domain in cookie.get('domain', '') or cookie.get('domain', '').endswith(f'.{domain}')
            ]
            
            if domain_cookies:
                print(f"   æ£€æµ‹åˆ° {domain} çš„ {len(domain_cookies)} ä¸ªcookies")
                
                # ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶
                await self._save_domain_cookies(domain, domain_cookies, analysis_result)
                
                # ç«‹å³ä¸Šä¼ åˆ°æœåŠ¡å™¨
                await self._upload_domain_cookies_immediately(domain, domain_cookies, analysis_result)
                
        except Exception as e:
            print(f"å¤„ç†åŸŸåcookiesé”™è¯¯: {e}")

    async def _save_domain_cookies(self, domain, cookies, analysis_result):
        """ä¿å­˜åŸŸåcookiesåˆ°æœ¬åœ°æ–‡ä»¶"""
        try:
            cookies_dir = Path("browser_data")
            cookies_dir.mkdir(exist_ok=True)
            
            domain_safe = re.sub(r'[^\w\-_.]', '_', domain)
            cookies_file = cookies_dir / f"{domain_safe}_cookies.json"
            
            cookies_data = {
                "domain": domain,
                "cookies": cookies,
                "analysis": analysis_result,
                "timestamp": time.time(),
                "count": len(cookies)
            }
            
            with cookies_file.open('w', encoding='utf-8') as f:
                json.dump(cookies_data, f, ensure_ascii=False, indent=2)
            
            print(f"   âœ… å·²ä¿å­˜åˆ°æœ¬åœ°: {cookies_file}")
            
        except Exception as e:
            print(f"ä¿å­˜åŸŸåcookieså¤±è´¥: {e}")

    async def _upload_domain_cookies_immediately(self, domain, cookies, analysis_result):
        """ç«‹å³ä¸Šä¼ å•ä¸ªåŸŸåçš„cookiesåˆ°æœåŠ¡å™¨"""
        try:
            print(f"   ğŸš€ æ­£åœ¨ä¸Šä¼  {domain} çš„cookiesåˆ°æœåŠ¡å™¨...")
            
            # è·å–ç®¡ç†å‘˜å¯†é’¥
            admin_key_response = requests.get(f"{self.server_url}/admin/key", timeout=10)
            if admin_key_response.status_code != 200:
                print(f"   âŒ æ— æ³•è·å–ç®¡ç†å‘˜å¯†é’¥: HTTP {admin_key_response.status_code}")
                return False
            
            admin_key = admin_key_response.json()["admin_key"]
            
            # æ„å»ºæŒ‰åŸŸååˆ†ç»„çš„cookiesæ•°æ®
            cookies_by_domain = {domain: cookies}
            
            # å‡†å¤‡æ™ºèƒ½ä¸Šä¼ æ•°æ®
            upload_data = {
                "cookies_by_domain": cookies_by_domain,
                "analysis": analysis_result,
                "strategy": analysis_result.get('strategy', self.analyzer.strategies['standard_shared']),
                "timestamp": time.time()
            }
            
            headers = {
                "X-Admin-Key": admin_key,
                "Content-Type": "application/json"
            }
            
            # ä¸Šä¼ åˆ°æ™ºèƒ½cookiesç®¡ç†ç«¯ç‚¹
            response = requests.post(
                f"{self.server_url}/admin/cookies/smart-import",
                json=upload_data,
                headers=headers,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                print(f"   âœ… {domain} cookiesä¸Šä¼ æˆåŠŸ!")
                print(f"   ğŸ“Š å¤„ç†ç»“æœ: {result.get('message', 'å·²å¤„ç†')}")
                
                # æ˜¾ç¤ºç­–ç•¥åº”ç”¨ç»“æœ
                strategy_result = result.get('strategy_applied', {})
                if strategy_result:
                    print(f"   ğŸ¯ åº”ç”¨ç­–ç•¥: {strategy_result.get('name', 'æœªçŸ¥ç­–ç•¥')}")
                
                return True
            else:
                print(f"   âŒ ä¸Šä¼ å¤±è´¥: HTTP {response.status_code}")
                if response.text:
                    print(f"   é”™è¯¯è¯¦æƒ…: {response.text[:200]}")
                return False
                
        except Exception as e:
            print(f"   âŒ ä¸Šä¼  {domain} cookieså¤±è´¥: {e}")
            return False

    async def _final_cookie_processing(self, context):
        """æœ€ç»ˆå¤„ç†æ‰€æœ‰cookies"""
        try:
            print("\nğŸ“Š å¼€å§‹æœ€ç»ˆcookieså¤„ç†...")
            
            # è·å–æ‰€æœ‰cookies
            all_cookies = await context.cookies()
            
            if not all_cookies:
                print("âŒ æœªæ£€æµ‹åˆ°ä»»ä½•cookies")
                return False
            
            # æŒ‰åŸŸååˆ†ç»„
            cookies_by_domain = {}
            for cookie in all_cookies:
                domain = cookie.get('domain', '').lstrip('.')
                if domain:
                    if domain not in cookies_by_domain:
                        cookies_by_domain[domain] = []
                    cookies_by_domain[domain].append(cookie)
            
            print(f"ğŸ“‹ æ€»è®¡æ£€æµ‹åˆ° {len(cookies_by_domain)} ä¸ªåŸŸåçš„cookies:")
            for domain, domain_cookies in cookies_by_domain.items():
                print(f"   {domain}: {len(domain_cookies)} ä¸ªcookies")
            
            # é€‰æ‹©ä¸»è¦åŸŸåè¿›è¡Œä¸Šä¼ 
            main_domain = self._select_main_domain(cookies_by_domain)
            if main_domain:
                # åˆ›å»ºç»¼åˆåˆ†æç»“æœ
                analysis_result = {
                    'domain': main_domain,
                    'site_type': {'type': 'enterprise_query', 'strategy': 'shared_enterprise'},
                    'strategy': self.analyzer.strategies['shared_enterprise'],
                    'timestamp': time.time()
                }
                
                # ä¸Šä¼ åˆ°æœåŠ¡å™¨
                success = await self._upload_smart_cookies(cookies_by_domain, analysis_result)
                return success
            else:
                print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„ä¸»åŸŸå")
                return False
                
        except Exception as e:
            print(f"æœ€ç»ˆå¤„ç†å¤±è´¥: {e}")
            return False

    def _select_main_domain(self, cookies_by_domain):
        """é€‰æ‹©ä¸»è¦åŸŸå"""
        # ä¼˜å…ˆé€‰æ‹©å·²æ£€æµ‹åˆ°ç™»å½•çš„åŸŸå
        if self.login_detected_domains:
            for domain in self.login_detected_domains:
                if domain in cookies_by_domain:
                    return domain
        
        # å¦åˆ™é€‰æ‹©cookiesæœ€å¤šçš„åŸŸå
        if cookies_by_domain:
            return max(cookies_by_domain.keys(), key=lambda d: len(cookies_by_domain[d]))
        
        return None

    async def _upload_smart_cookies(self, cookies_by_domain: Dict, analysis_result: Dict) -> bool:
        """æ™ºèƒ½ä¸Šä¼ cookiesåˆ°æœåŠ¡å™¨"""
        try:
            print("æ­£åœ¨ä¸Šä¼ cookiesåˆ°æœåŠ¡å™¨...")
            
            # è·å–ç®¡ç†å‘˜å¯†é’¥
            admin_key_response = requests.get(f"{self.server_url}/admin/key", timeout=10)
            if admin_key_response.status_code != 200:
                print("æ— æ³•è·å–ç®¡ç†å‘˜å¯†é’¥")
                return False
            
            admin_key = admin_key_response.json()["admin_key"]
            
            # å‡†å¤‡æ™ºèƒ½ä¸Šä¼ æ•°æ®
            upload_data = {
                "cookies_by_domain": cookies_by_domain,
                "analysis": analysis_result,
                "strategy": analysis_result['strategy'],
                "timestamp": time.time()
            }
            
            headers = {
                "X-Admin-Key": admin_key,
                "Content-Type": "application/json"
            }
            
            # ä¸Šä¼ åˆ°æ™ºèƒ½cookiesç®¡ç†ç«¯ç‚¹
            response = requests.post(
                f"{self.server_url}/admin/cookies/smart-import",
                json=upload_data,
                headers=headers,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                print(f"æ™ºèƒ½cookiesä¸Šä¼ æˆåŠŸ")
                print(f"å¤„ç†ç»“æœ: {result.get('message', 'å·²å¤„ç†')}")
                
                # æ˜¾ç¤ºç­–ç•¥åº”ç”¨ç»“æœ
                strategy_result = result.get('strategy_applied', {})
                if strategy_result:
                    print(f"ç­–ç•¥åº”ç”¨: {strategy_result}")
                
                return True
            else:
                print(f"ä¸Šä¼ cookieså¤±è´¥: HTTP {response.status_code}")
                if response.text:
                    print(f"é”™è¯¯ä¿¡æ¯: {response.text}")
                return False
                
        except Exception as e:
            print(f"ä¸Šä¼ cookiesåˆ°æœåŠ¡å™¨å¤±è´¥: {e}")
            return False


async def main():
    parser = argparse.ArgumentParser(description="æ™ºèƒ½æµè§ˆå™¨ç™»å½•å·¥å…·")
    parser.add_argument("--server", default="http://localhost:8001", help="æœåŠ¡å™¨åœ°å€")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦è¿è¡Œ
    try:
        response = requests.get(f"{args.server}/health", timeout=5)
        if response.status_code == 200:
            print("æœåŠ¡å™¨è¿æ¥æ­£å¸¸")
        else:
            print("æœåŠ¡å™¨å“åº”å¼‚å¸¸")
    except Exception as e:
        print(f"æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨ {args.server}")
        print(f"è¯·ç¡®ä¿æœåŠ¡å™¨æ­£åœ¨è¿è¡Œ: {e}")
        sys.exit(1)
    
    # å¼€å§‹æ™ºèƒ½ç™»å½•æµç¨‹
    smart_login = SmartBrowserLogin(args.server)
    success = await smart_login.start_smart_login()
    
    if success:
        print("\næ™ºèƒ½ç™»å½•å’Œcookiesç®¡ç†å®Œæˆï¼")
        print("ç³»ç»Ÿå·²æ ¹æ®ç½‘ç«™ç±»å‹åº”ç”¨æœ€ä½³ç­–ç•¥ã€‚")
    else:
        print("\næ™ºèƒ½ç™»å½•å¤±è´¥")
        print("è¯·æ£€æŸ¥ç™»å½•çŠ¶æ€å’Œç½‘ç»œè¿æ¥ã€‚")

if __name__ == "__main__":
    asyncio.run(main()) 